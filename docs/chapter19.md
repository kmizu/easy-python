# ç¬¬19ç« ï¼šPythonæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å®åº«

Pythonã«ã¯ã€Œãƒãƒƒãƒ†ãƒªãƒ¼åŒæ¢±ã€ã¨ã„ã†å“²å­¦ãŒã‚ã‚Šã¾ã™ã€‚ã¤ã¾ã‚Šã€ã‚ˆãä½¿ã‚ã‚Œã‚‹æ©Ÿèƒ½ã®å¤šããŒæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã—ã¦æœ€åˆã‹ã‚‰ç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ç« ã§ã¯ã€**Pythonæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª**ã®ä¸»è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å­¦ã³ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã€æ—¥æ™‚æ“ä½œã€JSONå‡¦ç†ã€æ­£è¦è¡¨ç¾ã€ãƒ‡ãƒ¼ã‚¿æ§‹é€ ãªã©ã‚’ä½¿ã£ãŸå®Ÿç”¨çš„ãªãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä½œã‚ŠãªãŒã‚‰ã€åŠ¹ç‡çš„ãªé–‹ç™ºæ‰‹æ³•ã‚’ç¿’å¾—ã—ã¾ã—ã‚‡ã†ã€‚

## æ—¥æ™‚å‡¦ç† - datetimeãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### åŸºæœ¬çš„ãªæ—¥æ™‚æ“ä½œ

```python
>>> import datetime
>>> from datetime import datetime, date, time, timedelta
>>> import calendar

>>> def demonstrate_datetime_basics():
...     """æ—¥æ™‚å‡¦ç†ã®åŸºæœ¬çš„ãªæ“ä½œ"""
...     print("=== æ—¥æ™‚å‡¦ç†ã®åŸºæœ¬ ===")
...     
...     # ç¾åœ¨ã®æ—¥æ™‚å–å¾—
...     now = datetime.now()
...     today = date.today()
...     
...     print(f"ç¾åœ¨æ—¥æ™‚: {now}")
...     print(f"ä»Šæ—¥ã®æ—¥ä»˜: {today}")
...     print(f"ç¾åœ¨æ™‚åˆ»: {now.time()}")
...     
...     # ç‰¹å®šã®æ—¥æ™‚ã‚’ä½œæˆ
...     birthday = datetime(1990, 5, 15, 14, 30, 0)
...     print(f"æŒ‡å®šã—ãŸæ—¥æ™‚: {birthday}")
...     
...     # æ—¥æ™‚ã®å„è¦ç´ ã‚’å–å¾—
...     print(f"å¹´: {now.year}")
...     print(f"æœˆ: {now.month}")
...     print(f"æ—¥: {now.day}")
...     print(f"æ›œæ—¥ç•ªå·: {now.weekday()} (æœˆæ›œæ—¥=0)")
...     print(f"æ›œæ—¥å: {calendar.day_name[now.weekday()]}")
...     
...     # æ–‡å­—åˆ—ã¨ã®å¤‰æ›
...     date_string = now.strftime("%Yå¹´%mæœˆ%dæ—¥ %Hæ™‚%Måˆ†%Sç§’")
...     print(f"ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿æ—¥æ™‚: {date_string}")
...     
...     # æ–‡å­—åˆ—ã‹ã‚‰æ—¥æ™‚ã¸ã®å¤‰æ›
...     parsed_date = datetime.strptime("2024-01-15 09:30:00", "%Y-%m-%d %H:%M:%S")
...     print(f"æ–‡å­—åˆ—ã‹ã‚‰å¤‰æ›: {parsed_date}")

>>> demonstrate_datetime_basics()

=== æ—¥æ™‚å‡¦ç†ã®åŸºæœ¬ ===
ç¾åœ¨æ—¥æ™‚: 2024-12-19 11:35:00.123456
ä»Šæ—¥ã®æ—¥ä»˜: 2024-12-19
ç¾åœ¨æ™‚åˆ»: 11:35:00.123456
æŒ‡å®šã—ãŸæ—¥æ™‚: 1990-05-15 14:30:00
å¹´: 2024
æœˆ: 12
æ—¥: 19
æ›œæ—¥ç•ªå·: 3 (æœˆæ›œæ—¥=0)
æ›œæ—¥å: Thursday
ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿æ—¥æ™‚: 2024å¹´12æœˆ19æ—¥ 11æ™‚35åˆ†00ç§’
æ–‡å­—åˆ—ã‹ã‚‰å¤‰æ›: 2024-01-15 09:30:00
```

### ã€å®Ÿè¡Œã€‘å‹¤æ€ ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã‚ã†

```python
>>> class AttendanceManager:
...     """å‹¤æ€ ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
...     
...     def __init__(self):
...         self.attendance_records = {}
...         self.holidays = set()
...         self.work_hours = {'start': time(9, 0), 'end': time(18, 0)}
...     
...     def add_holiday(self, holiday_date):
...         """ç¥æ—¥ã‚’è¿½åŠ """
...         if isinstance(holiday_date, str):
...             holiday_date = datetime.strptime(holiday_date, "%Y-%m-%d").date()
...         self.holidays.add(holiday_date)
...     
...     def clock_in(self, employee_id, timestamp=None):
...         """å‡ºå‹¤è¨˜éŒ²"""
...         if timestamp is None:
...             timestamp = datetime.now()
...         
...         date_key = timestamp.date()
...         if employee_id not in self.attendance_records:
...             self.attendance_records[employee_id] = {}
...         
...         if date_key in self.attendance_records[employee_id]:
...             return False, "æ—¢ã«å‡ºå‹¤è¨˜éŒ²ãŒã‚ã‚Šã¾ã™"
...         
...         self.attendance_records[employee_id][date_key] = {
...             'clock_in': timestamp,
...             'clock_out': None,
...             'break_start': None,
...             'break_end': None,
...             'notes': []
...         }
...         
...         # é…åˆ»ãƒã‚§ãƒƒã‚¯
...         standard_start = datetime.combine(date_key, self.work_hours['start'])
...         is_late = timestamp > standard_start
...         
...         if is_late:
...             late_minutes = int((timestamp - standard_start).total_seconds() / 60)
...             self.attendance_records[employee_id][date_key]['notes'].append(f"é…åˆ»: {late_minutes}åˆ†")
...         
...         return True, f"å‡ºå‹¤è¨˜éŒ²å®Œäº† ({timestamp.strftime('%H:%M')})"
...     
...     def clock_out(self, employee_id, timestamp=None):
...         """é€€å‹¤è¨˜éŒ²"""
...         if timestamp is None:
...             timestamp = datetime.now()
...         
...         date_key = timestamp.date()
...         if (employee_id not in self.attendance_records or 
...             date_key not in self.attendance_records[employee_id]):
...             return False, "å‡ºå‹¤è¨˜éŒ²ãŒã‚ã‚Šã¾ã›ã‚“"
...         
...         record = self.attendance_records[employee_id][date_key]
...         if record['clock_out'] is not None:
...             return False, "æ—¢ã«é€€å‹¤è¨˜éŒ²ãŒã‚ã‚Šã¾ã™"
...         
...         record['clock_out'] = timestamp
...         
...         # æ—©é€€ãƒã‚§ãƒƒã‚¯
...         standard_end = datetime.combine(date_key, self.work_hours['end'])
...         if timestamp < standard_end:
...             early_minutes = int((standard_end - timestamp).total_seconds() / 60)
...             record['notes'].append(f"æ—©é€€: {early_minutes}åˆ†")
...         
...         return True, f"é€€å‹¤è¨˜éŒ²å®Œäº† ({timestamp.strftime('%H:%M')})"
...     
...     def take_break(self, employee_id, timestamp=None):
...         """ä¼‘æ†©é–‹å§‹è¨˜éŒ²"""
...         if timestamp is None:
...             timestamp = datetime.now()
...         
...         date_key = timestamp.date()
...         if (employee_id not in self.attendance_records or 
...             date_key not in self.attendance_records[employee_id]):
...             return False, "å‡ºå‹¤è¨˜éŒ²ãŒã‚ã‚Šã¾ã›ã‚“"
...         
...         record = self.attendance_records[employee_id][date_key]
...         if record['break_start'] is not None:
...             return False, "æ—¢ã«ä¼‘æ†©ä¸­ã§ã™"
...         
...         record['break_start'] = timestamp
...         return True, f"ä¼‘æ†©é–‹å§‹ ({timestamp.strftime('%H:%M')})"
...     
...     def end_break(self, employee_id, timestamp=None):
...         """ä¼‘æ†©çµ‚äº†è¨˜éŒ²"""
...         if timestamp is None:
...             timestamp = datetime.now()
...         
...         date_key = timestamp.date()
...         record = self.attendance_records[employee_id][date_key]
...         
...         if record['break_start'] is None:
...             return False, "ä¼‘æ†©è¨˜éŒ²ãŒã‚ã‚Šã¾ã›ã‚“"
...         if record['break_end'] is not None:
...             return False, "æ—¢ã«ä¼‘æ†©çµ‚äº†æ¸ˆã¿ã§ã™"
...         
...         record['break_end'] = timestamp
...         return True, f"ä¼‘æ†©çµ‚äº† ({timestamp.strftime('%H:%M')})"
...     
...     def calculate_work_hours(self, employee_id, target_date):
...         """å‹¤å‹™æ™‚é–“è¨ˆç®—"""
...         if isinstance(target_date, str):
...             target_date = datetime.strptime(target_date, "%Y-%m-%d").date()
...         
...         if (employee_id not in self.attendance_records or 
...             target_date not in self.attendance_records[employee_id]):
...             return None
...         
...         record = self.attendance_records[employee_id][target_date]
...         
...         if record['clock_in'] is None or record['clock_out'] is None:
...             return None
...         
...         # ç·å‹¤å‹™æ™‚é–“
...         total_time = record['clock_out'] - record['clock_in']
...         
...         # ä¼‘æ†©æ™‚é–“ã‚’å·®ã—å¼•ã
...         if record['break_start'] and record['break_end']:
...             break_time = record['break_end'] - record['break_start']
...             total_time -= break_time
...         
...         hours = total_time.total_seconds() / 3600
...         return round(hours, 2)
...     
...     def generate_monthly_report(self, employee_id, year, month):
...         """æœˆæ¬¡å‹¤æ€ ãƒ¬ãƒãƒ¼ãƒˆ"""
...         # å¯¾è±¡æœˆã®æ—¥ä»˜ç¯„å›²ã‚’å–å¾—
...         start_date = date(year, month, 1)
...         if month == 12:
...             end_date = date(year + 1, 1, 1) - timedelta(days=1)
...         else:
...             end_date = date(year, month + 1, 1) - timedelta(days=1)
...         
...         report = {
...             'employee_id': employee_id,
...             'year': year,
...             'month': month,
...             'work_days': 0,
...             'total_hours': 0,
...             'late_count': 0,
...             'early_leave_count': 0,
...             'daily_records': []
...         }
...         
...         current_date = start_date
...         while current_date <= end_date:
...             # åœŸæ—¥ç¥æ—¥ã‚’ã‚¹ã‚­ãƒƒãƒ—
...             if (current_date.weekday() >= 5 or  # åœŸæ—¥
...                 current_date in self.holidays):  # ç¥æ—¥
...                 current_date += timedelta(days=1)
...                 continue
...             
...             daily_record = {
...                 'date': current_date,
...                 'work_hours': 0,
...                 'status': 'æ¬ å‹¤',
...                 'notes': []
...             }
...             
...             if (employee_id in self.attendance_records and 
...                 current_date in self.attendance_records[employee_id]):
...                 
...                 record = self.attendance_records[employee_id][current_date]
...                 work_hours = self.calculate_work_hours(employee_id, current_date)
...                 
...                 if work_hours is not None:
...                     daily_record['work_hours'] = work_hours
...                     daily_record['status'] = 'å‡ºå‹¤'
...                     report['work_days'] += 1
...                     report['total_hours'] += work_hours
...                 
...                 daily_record['notes'] = record.get('notes', [])
...                 
...                 # é…åˆ»ãƒ»æ—©é€€ã‚«ã‚¦ãƒ³ãƒˆ
...                 for note in daily_record['notes']:
...                     if 'é…åˆ»' in note:
...                         report['late_count'] += 1
...                     elif 'æ—©é€€' in note:
...                         report['early_leave_count'] += 1
...             
...             report['daily_records'].append(daily_record)
...             current_date += timedelta(days=1)
...         
...         return report
...     
...     def get_attendance_summary(self, employee_id):
...         """å‹¤æ€ ã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
...         if employee_id not in self.attendance_records:
...             return None
...         
...         total_days = 0
...         total_hours = 0
...         late_days = 0
...         
...         for date_key, record in self.attendance_records[employee_id].items():
...             if record['clock_in'] and record['clock_out']:
...                 total_days += 1
...                 work_hours = self.calculate_work_hours(employee_id, date_key)
...                 if work_hours:
...                     total_hours += work_hours
...                 
...                 for note in record.get('notes', []):
...                     if 'é…åˆ»' in note:
...                         late_days += 1
...                         break
...         
...         return {
...             'total_work_days': total_days,
...             'total_work_hours': round(total_hours, 2),
...             'average_hours_per_day': round(total_hours / total_days, 2) if total_days > 0 else 0,
...             'late_days': late_days,
...             'punctuality_rate': round((total_days - late_days) / total_days * 100, 1) if total_days > 0 else 100
...         }

>>> # å‹¤æ€ ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
>>> def test_attendance_system():
...     """å‹¤æ€ ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
...     print("=== å‹¤æ€ ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ ===")
...     
...     # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
...     attendance = AttendanceManager()
...     
...     # ç¥æ—¥ã®è¨­å®š
...     attendance.add_holiday("2024-01-01")  # å…ƒæ—¥
...     attendance.add_holiday("2024-01-08")  # æˆäººã®æ—¥
...     
...     # å¾“æ¥­å“¡ã®å‹¤æ€ è¨˜éŒ²ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
...     employee_id = "EMP001"
...     
...     # 1é€±é–“åˆ†ã®å‹¤æ€ ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
...     base_date = datetime(2024, 1, 15)  # æœˆæ›œæ—¥
...     
...     for day_offset in range(5):  # å¹³æ—¥5æ—¥åˆ†
...         work_date = base_date + timedelta(days=day_offset)
...         
...         # å‡ºå‹¤æ™‚åˆ»ï¼ˆãŸã¾ã«é…åˆ»ï¼‰
...         if day_offset == 2:  # æ°´æ›œæ—¥ã¯é…åˆ»
...             clock_in_time = work_date.replace(hour=9, minute=15)
...         else:
...             clock_in_time = work_date.replace(hour=8, minute=55)
...         
...         # é€€å‹¤æ™‚åˆ»
...         clock_out_time = work_date.replace(hour=18, minute=10)
...         
...         # ä¼‘æ†©æ™‚åˆ»
...         break_start = work_date.replace(hour=12, minute=0)
...         break_end = work_date.replace(hour=13, minute=0)
...         
...         # è¨˜éŒ²
...         attendance.clock_in(employee_id, clock_in_time)
...         attendance.take_break(employee_id, break_start)
...         attendance.end_break(employee_id, break_end)
...         attendance.clock_out(employee_id, clock_out_time)
...     
...     print("1é€±é–“ã®å‹¤æ€ ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜éŒ²ã—ã¾ã—ãŸ")
...     
...     # å„æ—¥ã®å‹¤å‹™æ™‚é–“ã‚’è¡¨ç¤º
...     print("\\n=== æ—¥åˆ¥å‹¤å‹™æ™‚é–“ ===")
...     for day_offset in range(5):
...         work_date = base_date + timedelta(days=day_offset)
...         work_hours = attendance.calculate_work_hours(employee_id, work_date.date())
...         day_name = calendar.day_name[work_date.weekday()]
...         print(f"{work_date.strftime('%Y-%m-%d')} ({day_name}): {work_hours}æ™‚é–“")
...     
...     # æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
...     monthly_report = attendance.generate_monthly_report(employee_id, 2024, 1)
...     
...     print(f"\\n=== æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆ (2024å¹´1æœˆ) ===")
...     print(f"å‡ºå‹¤æ—¥æ•°: {monthly_report['work_days']}æ—¥")
...     print(f"ç·å‹¤å‹™æ™‚é–“: {monthly_report['total_hours']}æ™‚é–“")
...     print(f"å¹³å‡å‹¤å‹™æ™‚é–“: {monthly_report['total_hours'] / monthly_report['work_days']:.2f}æ™‚é–“/æ—¥")
...     print(f"é…åˆ»å›æ•°: {monthly_report['late_count']}å›")
...     print(f"æ—©é€€å›æ•°: {monthly_report['early_leave_count']}å›")
...     
...     # å‹¤æ€ ã‚µãƒãƒªãƒ¼
...     summary = attendance.get_attendance_summary(employee_id)
...     print(f"\\n=== å‹¤æ€ ã‚µãƒãƒªãƒ¼ ===")
...     for key, value in summary.items():
...         print(f"{key}: {value}")

>>> test_attendance_system()

=== å‹¤æ€ ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ ===
1é€±é–“ã®å‹¤æ€ ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜éŒ²ã—ã¾ã—ãŸ

=== æ—¥åˆ¥å‹¤å‹™æ™‚é–“ ===
2024-01-15 (Monday): 8.25æ™‚é–“
2024-01-16 (Tuesday): 8.25æ™‚é–“
2024-01-17 (Wednesday): 8.0æ™‚é–“
2024-01-18 (Thursday): 8.25æ™‚é–“
2024-01-19 (Friday): 8.25æ™‚é–“

=== æœˆæ¬¡ãƒ¬ãƒãƒ¼ãƒˆ (2024å¹´1æœˆ) ===
å‡ºå‹¤æ—¥æ•°: 5æ—¥
ç·å‹¤å‹™æ™‚é–“: 41.0æ™‚é–“
å¹³å‡å‹¤å‹™æ™‚é–“: 8.20æ™‚é–“/æ—¥
é…åˆ»å›æ•°: 1å›
æ—©é€€å›æ•°: 0å›

=== å‹¤æ€ ã‚µãƒãƒªãƒ¼ ===
total_work_days: 5
total_work_hours: 41.0
average_hours_per_day: 8.2
late_days: 1
punctuality_rate: 80.0
```

## ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ“ä½œ - os/pathlibãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®åŸºæœ¬æ“ä½œ

```python
>>> import os
>>> import shutil
>>> from pathlib import Path
>>> import glob

>>> class FileSystemManager:
...     """ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†ã‚¯ãƒ©ã‚¹"""
...     
...     def __init__(self, base_directory="./file_operations"):
...         self.base_dir = Path(base_directory)
...         self.ensure_base_directory()
...     
...     def ensure_base_directory(self):
...         """ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºä¿"""
...         self.base_dir.mkdir(exist_ok=True)
...     
...     def create_directory_structure(self):
...         """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ä½œæˆ"""
...         directories = [
...             "documents/reports",
...             "documents/presentations", 
...             "images/photos",
...             "images/graphics",
...             "data/csv",
...             "data/json",
...             "backup"
...         ]
...         
...         for dir_path in directories:
...             full_path = self.base_dir / dir_path
...             full_path.mkdir(parents=True, exist_ok=True)
...         
...         print(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä½œæˆã—ã¾ã—ãŸ: {self.base_dir}")
...     
...     def create_sample_files(self):
...         """ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ"""
...         sample_files = {
...             "documents/reports/quarterly_report.txt": "å››åŠæœŸãƒ¬ãƒãƒ¼ãƒˆã®å†…å®¹\\nå£²ä¸Š: 1000ä¸‡å††\\nåˆ©ç›Š: 200ä¸‡å††",
...             "documents/reports/annual_summary.txt": "å¹´æ¬¡ã‚µãƒãƒªãƒ¼\\nç·å£²ä¸Š: 4000ä¸‡å††\\næˆé•·ç‡: 15%",
...             "documents/presentations/product_demo.txt": "è£½å“ãƒ‡ãƒ¢è³‡æ–™\\næ–°æ©Ÿèƒ½ã®ç´¹ä»‹\\nãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã®å‘ä¸Š",
...             "data/csv/sales_data.csv": "æ—¥ä»˜,å£²ä¸Š,å•†å“\\n2024-01-01,10000,å•†å“A\\n2024-01-02,15000,å•†å“B",
...             "data/json/config.json": '{"database": "mysql", "host": "localhost", "port": 3306}',
...             "images/photos/vacation.jpg": "ç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰",
...             "README.md": "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®èª¬æ˜\\n\\nã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯...\\n\\n## ä½¿ã„æ–¹\\n\\n1. è¨­å®š\\n2. å®Ÿè¡Œ"
...         }
...         
...         for file_path, content in sample_files.items():
...             full_path = self.base_dir / file_path
...             full_path.write_text(content, encoding='utf-8')
...         
...         print(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {len(sample_files)}å€‹")
...     
...     def list_directory_contents(self, directory=None, recursive=False):
...         """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹ã®ä¸€è¦§è¡¨ç¤º"""
...         if directory is None:
...             directory = self.base_dir
...         else:
...             directory = self.base_dir / directory
...         
...         if not directory.exists():
...             return f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {directory}"
...         
...         contents = []
...         
...         if recursive:
...             # å†å¸°çš„ã«å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
...             for item in directory.rglob("*"):
...                 if item.is_file():
...                     relative_path = item.relative_to(self.base_dir)
...                     file_size = item.stat().st_size
...                     contents.append({
...                         'path': str(relative_path),
...                         'size': file_size,
...                         'type': 'file'
...                     })
...                 elif item.is_dir() and item != directory:
...                     relative_path = item.relative_to(self.base_dir)
...                     contents.append({
...                         'path': str(relative_path),
...                         'type': 'directory'
...                     })
...         else:
...             # ç›´ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã¿
...             for item in directory.iterdir():
...                 relative_path = item.relative_to(self.base_dir)
...                 if item.is_file():
...                     file_size = item.stat().st_size
...                     contents.append({
...                         'path': str(relative_path),
...                         'size': file_size,
...                         'type': 'file'
...                     })
...                 else:
...                     contents.append({
...                         'path': str(relative_path),
...                         'type': 'directory'
...                     })
...         
...         return contents
...     
...     def find_files_by_pattern(self, pattern):
...         """ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢"""
...         matches = []
...         for file_path in self.base_dir.rglob(pattern):
...             if file_path.is_file():
...                 relative_path = file_path.relative_to(self.base_dir)
...                 matches.append({
...                     'path': str(relative_path),
...                     'size': file_path.stat().st_size,
...                     'modified': datetime.fromtimestamp(file_path.stat().st_mtime)
...                 })
...         return matches
...     
...     def get_file_info(self, file_path):
...         """ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®å–å¾—"""
...         full_path = self.base_dir / file_path
...         if not full_path.exists():
...             return None
...         
...         stat_info = full_path.stat()
...         
...         return {
...             'path': str(file_path),
...             'size': stat_info.st_size,
...             'created': datetime.fromtimestamp(stat_info.st_ctime),
...             'modified': datetime.fromtimestamp(stat_info.st_mtime),
...             'is_file': full_path.is_file(),
...             'is_directory': full_path.is_dir(),
...             'extension': full_path.suffix,
...             'stem': full_path.stem
...         }
...     
...     def backup_files(self, backup_name=None):
...         """ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
...         if backup_name is None:
...             backup_name = f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
...         
...         backup_dir = self.base_dir / "backup" / backup_name
...         backup_dir.mkdir(parents=True, exist_ok=True)
...         
...         copied_files = 0
...         for item in self.base_dir.rglob("*"):
...             if item.is_file() and "backup" not in str(item):
...                 relative_path = item.relative_to(self.base_dir)
...                 backup_path = backup_dir / relative_path
...                 backup_path.parent.mkdir(parents=True, exist_ok=True)
...                 shutil.copy2(item, backup_path)
...                 copied_files += 1
...         
...         return f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {copied_files}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ {backup_name} ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ"
...     
...     def calculate_directory_size(self, directory=None):
...         """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚ºã®è¨ˆç®—"""
...         if directory is None:
...             directory = self.base_dir
...         else:
...             directory = self.base_dir / directory
...         
...         total_size = 0
...         file_count = 0
...         
...         for file_path in directory.rglob("*"):
...             if file_path.is_file():
...                 total_size += file_path.stat().st_size
...                 file_count += 1
...         
...         return {
...             'total_size_bytes': total_size,
...             'total_size_mb': round(total_size / (1024 * 1024), 2),
...             'file_count': file_count
...         }
...     
...     def organize_files_by_extension(self):
...         """æ‹¡å¼µå­åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†"""
...         organized = {}
...         
...         for file_path in self.base_dir.rglob("*"):
...             if file_path.is_file() and "backup" not in str(file_path):
...                 extension = file_path.suffix.lower()
...                 if not extension:
...                     extension = "no_extension"
...                 
...                 if extension not in organized:
...                     organized[extension] = []
...                 
...                 organized[extension].append({
...                     'name': file_path.name,
...                     'path': str(file_path.relative_to(self.base_dir)),
...                     'size': file_path.stat().st_size
...                 })
...         
...         return organized
...     
...     def cleanup(self):
...         """ä½œæˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‰Šé™¤"""
...         if self.base_dir.exists():
...             shutil.rmtree(self.base_dir)
...             print(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {self.base_dir}")

>>> # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†ã®ãƒ†ã‚¹ãƒˆ
>>> def test_file_system_operations():
...     """ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ æ“ä½œã®ãƒ†ã‚¹ãƒˆ"""
...     print("=== ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ æ“ä½œã®ãƒ†ã‚¹ãƒˆ ===")
...     
...     # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†ã®åˆæœŸåŒ–
...     fs_manager = FileSystemManager()
...     
...     # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
...     fs_manager.create_directory_structure()
...     fs_manager.create_sample_files()
...     
...     # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹ã®è¡¨ç¤º
...     print("\\n=== ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹ ===")
...     root_contents = fs_manager.list_directory_contents()
...     for item in root_contents:
...         icon = "ğŸ“" if item['type'] == 'directory' else "ğŸ“„"
...         size_info = f" ({item['size']} bytes)" if item['type'] == 'file' else ""
...         print(f"{icon} {item['path']}{size_info}")
...     
...     # å†å¸°çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
...     print("\\n=== å…¨ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ ===")
...     all_files = fs_manager.list_directory_contents(recursive=True)
...     for item in all_files:
...         if item['type'] == 'file':
...             print(f"ğŸ“„ {item['path']} ({item['size']} bytes)")
...     
...     # ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œç´¢
...     print("\\n=== .txt ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢ ===")
...     txt_files = fs_manager.find_files_by_pattern("*.txt")
...     for file_info in txt_files:
...         print(f"ğŸ“„ {file_info['path']} - {file_info['size']} bytes, æ›´æ–°æ—¥: {file_info['modified'].strftime('%Y-%m-%d %H:%M')}")
...     
...     # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®å–å¾—
...     print("\\n=== README.md ã®è©³ç´°æƒ…å ± ===")
...     readme_info = fs_manager.get_file_info("README.md")
...     if readme_info:
...         for key, value in readme_info.items():
...             print(f"{key}: {value}")
...     
...     # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚ºè¨ˆç®—
...     total_size = fs_manager.calculate_directory_size()
...     print(f"\\n=== ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚º ===")
...     print(f"ç·ã‚µã‚¤ã‚º: {total_size['total_size_mb']} MB ({total_size['total_size_bytes']} bytes)")
...     print(f"ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_size['file_count']}")
...     
...     # æ‹¡å¼µå­åˆ¥æ•´ç†
...     print("\\n=== æ‹¡å¼µå­åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç† ===")
...     organized_files = fs_manager.organize_files_by_extension()
...     for extension, files in organized_files.items():
...         print(f"\\n{extension}: {len(files)}å€‹")
...         for file_info in files:
...             print(f"  ğŸ“„ {file_info['name']} ({file_info['size']} bytes)")
...     
...     # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
...     backup_result = fs_manager.backup_files()
...     print(f"\\n{backup_result}")
...     
...     # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆãƒ†ã‚¹ãƒˆå¾Œã®å‰Šé™¤ï¼‰
...     # fs_manager.cleanup()  # å®Ÿéš›ã«ã¯å‰Šé™¤ã—ãªã„ï¼ˆç¢ºèªç”¨ï¼‰
...     print("\\nãƒ†ã‚¹ãƒˆå®Œäº†ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã¯æ®‹ã•ã‚Œã¦ã„ã¾ã™ï¼‰")

>>> test_file_system_operations()

=== ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ æ“ä½œã®ãƒ†ã‚¹ãƒˆ ===
ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä½œæˆã—ã¾ã—ãŸ: file_operations
ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: 7å€‹

=== ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹ ===
ğŸ“ backup
ğŸ“ data
ğŸ“ documents
ğŸ“ images
ğŸ“„ README.md (75 bytes)

=== å…¨ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ ===
ğŸ“„ README.md (75 bytes)
ğŸ“„ data/csv/sales_data.csv (82 bytes)
ğŸ“„ data/json/config.json (71 bytes)
ğŸ“„ documents/presentations/product_demo.txt (54 bytes)
ğŸ“„ documents/reports/annual_summary.txt (42 bytes)
ğŸ“„ documents/reports/quarterly_report.txt (58 bytes)
ğŸ“„ images/photos/vacation.jpg (39 bytes)

=== .txt ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢ ===
ğŸ“„ documents/presentations/product_demo.txt - 54 bytes, æ›´æ–°æ—¥: 2024-12-19 11:40
ğŸ“„ documents/reports/annual_summary.txt - 42 bytes, æ›´æ–°æ—¥: 2024-12-19 11:40
ğŸ“„ documents/reports/quarterly_report.txt - 58 bytes, æ›´æ–°æ—¥: 2024-12-19 11:40

=== README.md ã®è©³ç´°æƒ…å ± ===
path: README.md
size: 75
created: 2024-12-19 11:40:00.123456
modified: 2024-12-19 11:40:00.123456
is_file: True
is_directory: False
extension: .md
stem: README

=== ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚º ===
ç·ã‚µã‚¤ã‚º: 0.0 MB (421 bytes)
ãƒ•ã‚¡ã‚¤ãƒ«æ•°: 7

=== æ‹¡å¼µå­åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç† ===

.md: 1å€‹
  ğŸ“„ README.md (75 bytes)

.csv: 1å€‹
  ğŸ“„ sales_data.csv (82 bytes)

.json: 1å€‹
  ğŸ“„ config.json (71 bytes)

.txt: 3å€‹
  ğŸ“„ product_demo.txt (54 bytes)
  ğŸ“„ annual_summary.txt (42 bytes)
  ğŸ“„ quarterly_report.txt (58 bytes)

.jpg: 1å€‹
  ğŸ“„ vacation.jpg (39 bytes)

ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: 7å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ backup_20241219_114000 ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ

ãƒ†ã‚¹ãƒˆå®Œäº†ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã¯æ®‹ã•ã‚Œã¦ã„ã¾ã™ï¼‰
```

## JSONå‡¦ç† - jsonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### ã€å®Ÿè¡Œã€‘è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

```python
>>> import json
>>> from pathlib import Path
>>> from typing import Dict, Any

>>> class ConfigurationManager:
...     """è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
...     
...     def __init__(self, config_file="config.json"):
...         self.config_file = Path(config_file)
...         self.config_data = {}
...         self.load_config()
...     
...     def load_config(self):
...         """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
...         if self.config_file.exists():
...             try:
...                 with open(self.config_file, 'r', encoding='utf-8') as f:
...                     self.config_data = json.load(f)
...                 print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self.config_file}")
...             except json.JSONDecodeError as e:
...                 print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚¨ãƒ©ãƒ¼: {e}")
...                 self.config_data = {}
...             except Exception as e:
...                 print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
...                 self.config_data = {}
...         else:
...             print("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
...             self.create_default_config()
...     
...     def create_default_config(self):
...         """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®ä½œæˆ"""
...         default_config = {
...             "application": {
...                 "name": "Sample Application",
...                 "version": "1.0.0",
...                 "debug": False,
...                 "log_level": "INFO"
...             },
...             "database": {
...                 "host": "localhost",
...                 "port": 5432,
...                 "name": "sample_db",
...                 "username": "user",
...                 "password": "password",
...                 "ssl_enabled": True,
...                 "connection_pool": {
...                     "min_connections": 5,
...                     "max_connections": 20
...                 }
...             },
...             "api": {
...                 "base_url": "https://api.example.com",
...                 "timeout": 30,
...                 "retry_attempts": 3,
...                 "rate_limit": {
...                     "requests_per_minute": 60,
...                     "requests_per_hour": 1000
...                 }
...             },
...             "cache": {
...                 "enabled": True,
...                 "type": "redis",
...                 "host": "localhost",
...                 "port": 6379,
...                 "ttl": 3600
...             },
...             "logging": {
...                 "file": "app.log",
...                 "max_file_size": "10MB",
...                 "backup_count": 5,
...                 "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
...             }
...         }
...         
...         self.config_data = default_config
...         self.save_config()
...     
...     def save_config(self):
...         """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜"""
...         try:
...             with open(self.config_file, 'w', encoding='utf-8') as f:
...                 json.dump(self.config_data, f, ensure_ascii=False, indent=2)
...             print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {self.config_file}")
...             return True
...         except Exception as e:
...             print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
...             return False
...     
...     def get_config(self, key_path, default=None):
...         """ãƒã‚¹ãƒˆã—ãŸã‚­ãƒ¼ã‹ã‚‰è¨­å®šå€¤ã‚’å–å¾—"""
...         keys = key_path.split('.')
...         current = self.config_data
...         
...         for key in keys:
...             if isinstance(current, dict) and key in current:
...                 current = current[key]
...             else:
...                 return default
...         
...         return current
...     
...     def set_config(self, key_path, value):
...         """ãƒã‚¹ãƒˆã—ãŸã‚­ãƒ¼ã«è¨­å®šå€¤ã‚’è¨­å®š"""
...         keys = key_path.split('.')
...         current = self.config_data
...         
...         # æœ€å¾Œã®ã‚­ãƒ¼ä»¥å¤–ã‚’ãŸã©ã£ã¦ãƒã‚¹ãƒˆã—ãŸè¾æ›¸ã‚’ä½œæˆ
...         for key in keys[:-1]:
...             if key not in current:
...                 current[key] = {}
...             current = current[key]
...         
...         # æœ€å¾Œã®ã‚­ãƒ¼ã«å€¤ã‚’è¨­å®š
...         current[keys[-1]] = value
...         return self.save_config()
...     
...     def update_config(self, updates: Dict[str, Any]):
...         """è¤‡æ•°ã®è¨­å®šã‚’ä¸€æ‹¬æ›´æ–°"""
...         for key_path, value in updates.items():
...             self.set_config(key_path, value)
...     
...     def validate_config(self):
...         """è¨­å®šã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
...         issues = []
...         
...         # å¿…é ˆé …ç›®ã®ãƒã‚§ãƒƒã‚¯
...         required_keys = [
...             'application.name',
...             'application.version',
...             'database.host',
...             'database.name'
...         ]
...         
...         for key in required_keys:
...             if self.get_config(key) is None:
...                 issues.append(f"å¿…é ˆé …ç›®ãŒæœªè¨­å®š: {key}")
...         
...         # ãƒ‡ãƒ¼ã‚¿å‹ã®ãƒã‚§ãƒƒã‚¯
...         type_checks = {
...             'database.port': int,
...             'api.timeout': (int, float),
...             'cache.enabled': bool,
...             'database.ssl_enabled': bool
...         }
...         
...         for key, expected_type in type_checks.items():
...             value = self.get_config(key)
...             if value is not None and not isinstance(value, expected_type):
...                 issues.append(f"ãƒ‡ãƒ¼ã‚¿å‹ã‚¨ãƒ©ãƒ¼: {key} ã¯ {expected_type.__name__} ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
...         
...         # ç¯„å›²ãƒã‚§ãƒƒã‚¯
...         range_checks = {
...             'database.port': (1, 65535),
...             'api.timeout': (1, 300),
...             'cache.port': (1, 65535)
...         }
...         
...         for key, (min_val, max_val) in range_checks.items():
...             value = self.get_config(key)
...             if value is not None and isinstance(value, (int, float)):
...                 if not (min_val <= value <= max_val):
...                     issues.append(f"ç¯„å›²ã‚¨ãƒ©ãƒ¼: {key} ã¯ {min_val} ã‹ã‚‰ {max_val} ã®é–“ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
...         
...         return issues
...     
...     def export_config(self, export_file, sections=None):
...         """è¨­å®šã®éƒ¨åˆ†çš„ãªã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
...         if sections is None:
...             export_data = self.config_data
...         else:
...             export_data = {}
...             for section in sections:
...                 if section in self.config_data:
...                     export_data[section] = self.config_data[section]
...         
...         try:
...             with open(export_file, 'w', encoding='utf-8') as f:
...                 json.dump(export_data, f, ensure_ascii=False, indent=2)
...             return True, f"è¨­å®šã‚’ {export_file} ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ"
...         except Exception as e:
...             return False, f"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}"
...     
...     def import_config(self, import_file, merge=True):
...         """è¨­å®šã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
...         try:
...             with open(import_file, 'r', encoding='utf-8') as f:
...                 imported_data = json.load(f)
...             
...             if merge:
...                 # æ—¢å­˜è¨­å®šã¨ãƒãƒ¼ã‚¸
...                 self._deep_merge(self.config_data, imported_data)
...             else:
...                 # å®Œå…¨ç½®æ›
...                 self.config_data = imported_data
...             
...             self.save_config()
...             return True, f"è¨­å®šã‚’ {import_file} ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ"
...         except Exception as e:
...             return False, f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}"
...     
...     def _deep_merge(self, target, source):
...         """è¾æ›¸ã®æ·±ã„ãƒãƒ¼ã‚¸"""
...         for key, value in source.items():
...             if key in target and isinstance(target[key], dict) and isinstance(value, dict):
...                 self._deep_merge(target[key], value)
...             else:
...                 target[key] = value
...     
...     def get_environment_specific_config(self, environment):
...         """ç’°å¢ƒå›ºæœ‰ã®è¨­å®šã‚’å–å¾—"""
...         env_config = self.config_data.copy()
...         
...         # ç’°å¢ƒå›ºæœ‰ã®è¨­å®šãŒã‚ã‚Œã°é©ç”¨
...         if f"environments.{environment}" in str(self.config_data):
...             env_specific = self.get_config(f"environments.{environment}", {})
...             self._deep_merge(env_config, env_specific)
...         
...         return env_config
...     
...     def generate_config_report(self):
...         """è¨­å®šãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
...         report = {
...             "config_file": str(self.config_file),
...             "file_size": self.config_file.stat().st_size if self.config_file.exists() else 0,
...             "last_modified": datetime.fromtimestamp(self.config_file.stat().st_mtime).isoformat() if self.config_file.exists() else None,
...             "sections": list(self.config_data.keys()),
...             "total_keys": self._count_keys(self.config_data),
...             "validation_issues": self.validate_config()
...         }
...         
...         return report
...     
...     def _count_keys(self, data, count=0):
...         """è¨­å®šé …ç›®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
...         if isinstance(data, dict):
...             for value in data.values():
...                 if isinstance(value, dict):
...                     count = self._count_keys(value, count)
...                 else:
...                     count += 1
...         return count

>>> # è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
>>> def test_configuration_system():
...     """è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
...     print("=== è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ ===")
...     
...     # è¨­å®šç®¡ç†ã®åˆæœŸåŒ–
...     config = ConfigurationManager("test_config.json")
...     
...     # è¨­å®šå€¤ã®å–å¾—
...     print("\\n=== è¨­å®šå€¤ã®å–å¾— ===")
...     app_name = config.get_config("application.name")
...     db_host = config.get_config("database.host")
...     api_timeout = config.get_config("api.timeout")
...     
...     print(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å: {app_name}")
...     print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ›ã‚¹ãƒˆ: {db_host}")
...     print(f"APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {api_timeout}ç§’")
...     
...     # è¨­å®šå€¤ã®å¤‰æ›´
...     print("\\n=== è¨­å®šå€¤ã®å¤‰æ›´ ===")
...     config.set_config("application.debug", True)
...     config.set_config("database.connection_pool.max_connections", 30)
...     config.set_config("api.base_url", "https://api-v2.example.com")
...     
...     print("ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã€æœ€å¤§æ¥ç¶šæ•°ã€APIãƒ™ãƒ¼ã‚¹URLã‚’å¤‰æ›´ã—ã¾ã—ãŸ")
...     
...     # ä¸€æ‹¬æ›´æ–°
...     print("\\n=== ä¸€æ‹¬è¨­å®šæ›´æ–° ===")
...     updates = {
...         "cache.ttl": 7200,
...         "logging.level": "DEBUG",
...         "api.rate_limit.requests_per_minute": 120
...     }
...     config.update_config(updates)
...     print("è¤‡æ•°ã®è¨­å®šã‚’ä¸€æ‹¬æ›´æ–°ã—ã¾ã—ãŸ")
...     
...     # è¨­å®šã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
...     print("\\n=== è¨­å®šã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ ===")
...     validation_issues = config.validate_config()
...     if validation_issues:
...         print("å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ã§å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
...         for issue in validation_issues:
...             print(f"  âš ï¸ {issue}")
...     else:
...         print("âœ“ è¨­å®šã¯æ­£å¸¸ã§ã™")
...     
...     # è¨­å®šãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
...     print("\\n=== è¨­å®šãƒ¬ãƒãƒ¼ãƒˆ ===")
...     report = config.generate_config_report()
...     print(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {report['config_file']}")
...     print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {report['file_size']} bytes")
...     print(f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(report['sections'])}")
...     print(f"ç·è¨­å®šé …ç›®æ•°: {report['total_keys']}")
...     print(f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³: {', '.join(report['sections'])}")
...     
...     # éƒ¨åˆ†ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
...     print("\\n=== éƒ¨åˆ†ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ ===")
...     success, message = config.export_config("database_config.json", ["database"])
...     print(message)
...     
...     # ç’°å¢ƒå›ºæœ‰è¨­å®šã®ä¾‹
...     print("\\n=== ç’°å¢ƒå›ºæœ‰è¨­å®šã®ä½œæˆ ===")
...     config.set_config("environments.production.database.host", "prod-db.example.com")
...     config.set_config("environments.production.application.debug", False)
...     config.set_config("environments.development.database.host", "dev-db.example.com")
...     config.set_config("environments.development.application.debug", True)
...     
...     # æœ¬ç•ªç’°å¢ƒç”¨è¨­å®š
...     prod_config = config.get_environment_specific_config("production")
...     print(f"æœ¬ç•ªç’°å¢ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ›ã‚¹ãƒˆ: {prod_config['database']['host']}")
...     print(f"æœ¬ç•ªç’°å¢ƒã®ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: {prod_config['application']['debug']}")

>>> test_configuration_system()

=== è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ ===
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: test_config.json

=== è¨­å®šå€¤ã®å–å¾— ===
ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å: Sample Application
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ›ã‚¹ãƒˆ: localhost
APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: 30

=== è¨­å®šå€¤ã®å¤‰æ›´ ===
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: test_config.json
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: test_config.json
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: test_config.json
ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã€æœ€å¤§æ¥ç¶šæ•°ã€APIãƒ™ãƒ¼ã‚¹URLã‚’å¤‰æ›´ã—ã¾ã—ãŸ

=== ä¸€æ‹¬è¨­å®šæ›´æ–° ===
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: test_config.json
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: test_config.json
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: test_config.json
è¤‡æ•°ã®è¨­å®šã‚’ä¸€æ‹¬æ›´æ–°ã—ã¾ã—ãŸ

=== è¨­å®šã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ ===
âœ“ è¨­å®šã¯æ­£å¸¸ã§ã™

=== è¨­å®šãƒ¬ãƒãƒ¼ãƒˆ ===
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: test_config.json
ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 1089 bytes
ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°: 5
ç·è¨­å®šé …ç›®æ•°: 25
ã‚»ã‚¯ã‚·ãƒ§ãƒ³: application, database, api, cache, logging

=== éƒ¨åˆ†ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ ===
è¨­å®šã‚’ database_config.json ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ

=== ç’°å¢ƒå›ºæœ‰è¨­å®šã®ä½œæˆ ===
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: test_config.json
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: test_config.json
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: test_config.json
è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: test_config.json
æœ¬ç•ªç’°å¢ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ›ã‚¹ãƒˆ: prod-db.example.com
æœ¬ç•ªç’°å¢ƒã®ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: False
```

## æ­£è¦è¡¨ç¾ - reãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### ã€å®Ÿè¡Œã€‘ãƒ†ã‚­ã‚¹ãƒˆè§£æã‚·ã‚¹ãƒ†ãƒ 

```python
>>> import re
>>> from collections import Counter
>>> from typing import List, Dict, Tuple

>>> class TextAnalyzer:
...     """ãƒ†ã‚­ã‚¹ãƒˆè§£æã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ­£è¦è¡¨ç¾ä½¿ç”¨ï¼‰"""
...     
...     def __init__(self):
...         # ã‚ˆãä½¿ç”¨ã™ã‚‹æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’äº‹å‰ã«å®šç¾©
...         self.patterns = {
...             'email': re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'),
...             'phone_jp': re.compile(r'0\d{1,4}-\d{1,4}-\d{4}'),
...             'url': re.compile(r'https?://[^\s<>"\'{}|\\^`\[\]]+'),
...             'postal_code': re.compile(r'\d{3}-\d{4}'),
...             'date_ymd': re.compile(r'\d{4}[-/]\d{1,2}[-/]\d{1,2}'),
...             'time_hm': re.compile(r'\d{1,2}:\d{2}'),
...             'number': re.compile(r'-?\d+(?:\.\d+)?'),
...             'word': re.compile(r'[A-Za-z]+'),
...             'japanese': re.compile(r'[ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠæ¼¢å­—]+', re.UNICODE)
...         }
...     
...     def extract_information(self, text: str) -> Dict[str, List[str]]:
...         """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å„ç¨®æƒ…å ±ã‚’æŠ½å‡º"""
...         results = {}
...         
...         for name, pattern in self.patterns.items():
...             matches = pattern.findall(text)
...             results[name] = matches
...         
...         return results
...     
...     def validate_format(self, text: str, format_type: str) -> bool:
...         """æŒ‡å®šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
...         if format_type not in self.patterns:
...             return False
...         
...         return bool(self.patterns[format_type].fullmatch(text))
...     
...     def clean_text(self, text: str) -> str:
...         """ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
...         # HTMLã‚¿ã‚°ã®é™¤å»
...         text = re.sub(r'<[^>]+>', '', text)
...         
...         # ä½™åˆ†ãªç©ºç™½ã®é™¤å»
...         text = re.sub(r'\s+', ' ', text)
...         
...         # è¡Œé ­ãƒ»è¡Œæœ«ã®ç©ºç™½é™¤å»
...         text = text.strip()
...         
...         return text
...     
...     def mask_sensitive_data(self, text: str) -> str:
...         """æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¹ã‚­ãƒ³ã‚°"""
...         # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®ãƒã‚¹ã‚­ãƒ³ã‚°
...         text = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', 
...                      '***@***.***', text)
...         
...         # é›»è©±ç•ªå·ã®ãƒã‚¹ã‚­ãƒ³ã‚°
...         text = re.sub(r'0\d{1,4}-\d{1,4}-\d{4}', '***-****-****', text)
...         
...         # éƒµä¾¿ç•ªå·ã®ãƒã‚¹ã‚­ãƒ³ã‚°
...         text = re.sub(r'\d{3}-\d{4}', '***-****', text)
...         
...         return text
...     
...     def extract_structured_data(self, text: str) -> Dict[str, List[Dict]]:
...         """æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º"""
...         # ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®æŠ½å‡º
...         log_pattern = re.compile(
...             r'(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\s+'
...             r'\[(?P<level>\w+)\]\s+'
...             r'(?P<message>.*)'
...         )
...         
...         # CSVå½¢å¼ã®æŠ½å‡º
...         csv_pattern = re.compile(
...             r'(?P<field1>[^,]+),\s*(?P<field2>[^,]+),\s*(?P<field3>[^,\n]+)'
...         )
...         
...         # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®æŠ½å‡º
...         user_pattern = re.compile(
...             r'åå‰:\s*(?P<name>[^\s]+)\s+'
...             r'å¹´é½¢:\s*(?P<age>\d+)\s+'
...             r'ãƒ¡ãƒ¼ãƒ«:\s*(?P<email>[^\s]+)'
...         )
...         
...         results = {
...             'logs': [],
...             'csv_data': [],
...             'users': []
...         }
...         
...         # ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®æŠ½å‡º
...         for match in log_pattern.finditer(text):
...             results['logs'].append(match.groupdict())
...         
...         # CSV ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
...         for match in csv_pattern.finditer(text):
...             results['csv_data'].append(match.groupdict())
...         
...         # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®æŠ½å‡º
...         for match in user_pattern.finditer(text):
...             results['users'].append(match.groupdict())
...         
...         return results
...     
...     def analyze_text_patterns(self, text: str) -> Dict[str, any]:
...         """ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
...         # å˜èªã®é »åº¦åˆ†æ
...         words = re.findall(r'\b\w+\b', text.lower())
...         word_freq = Counter(words)
...         
...         # æ–‡ã®é•·ã•åˆ†æ
...         sentences = re.split(r'[.!?]+', text)
...         sentence_lengths = [len(s.split()) for s in sentences if s.strip()]
...         
...         # æ®µè½åˆ†æ
...         paragraphs = re.split(r'\n\s*\n', text)
...         paragraph_count = len([p for p in paragraphs if p.strip()])
...         
...         # æ•°å€¤ã®çµ±è¨ˆ
...         numbers = [float(n) for n in re.findall(r'-?\d+(?:\.\d+)?', text)]
...         
...         return {
...             'word_count': len(words),
...             'unique_words': len(word_freq),
...             'most_common_words': word_freq.most_common(5),
...             'sentence_count': len(sentence_lengths),
...             'avg_sentence_length': sum(sentence_lengths) / len(sentence_lengths) if sentence_lengths else 0,
...             'paragraph_count': paragraph_count,
...             'number_count': len(numbers),
...             'number_sum': sum(numbers) if numbers else 0
...         }
...     
...     def search_and_replace(self, text: str, replacements: List[Tuple[str, str]]) -> str:
...         """æ¤œç´¢ã¨ç½®æ›ï¼ˆæ­£è¦è¡¨ç¾å¯¾å¿œï¼‰"""
...         result = text
...         for pattern, replacement in replacements:
...             result = re.sub(pattern, replacement, result)
...         return result
...     
...     def generate_summary_report(self, text: str) -> str:
...         """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
...         # åŸºæœ¬æƒ…å ±ã®æŠ½å‡º
...         extracted = self.extract_information(text)
...         patterns = self.analyze_text_patterns(text)
...         structured = self.extract_structured_data(text)
...         
...         report = [
...             "=== ãƒ†ã‚­ã‚¹ãƒˆè§£æãƒ¬ãƒãƒ¼ãƒˆ ===",
...             f"ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(text)}æ–‡å­—",
...             f"å˜èªæ•°: {patterns['word_count']}",
...             f"ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°: {patterns['unique_words']}",
...             f"æ–‡æ•°: {patterns['sentence_count']}",
...             f"æ®µè½æ•°: {patterns['paragraph_count']}",
...             "",
...             "ã€æŠ½å‡ºã•ã‚ŒãŸæƒ…å ±ã€‘"
...         ]
...         
...         for info_type, items in extracted.items():
...             if items:
...                 report.append(f"{info_type}: {len(items)}å€‹")
...                 for item in items[:3]:  # æœ€åˆã®3å€‹ã®ã¿è¡¨ç¤º
...                     report.append(f"  - {item}")
...                 if len(items) > 3:
...                     report.append(f"  ... ä»– {len(items) - 3}å€‹")
...         
...         if patterns['most_common_words']:
...             report.append("")
...             report.append("ã€é »å‡ºå˜èª TOP5ã€‘")
...             for word, count in patterns['most_common_words']:
...                 report.append(f"{word}: {count}å›")
...         
...         return "\n".join(report)

>>> # ãƒ†ã‚­ã‚¹ãƒˆè§£æã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
>>> def test_text_analyzer():
...     """ãƒ†ã‚­ã‚¹ãƒˆè§£æã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
...     print("=== ãƒ†ã‚­ã‚¹ãƒˆè§£æã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ ===")
...     
...     # ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã®æº–å‚™
...     sample_text = """
...     ä¼šç¤¾æƒ…å ±:
...     åå‰: ç”°ä¸­å¤ªéƒ å¹´é½¢: 30 ãƒ¡ãƒ¼ãƒ«: tanaka@example.com
...     åå‰: ä½è—¤èŠ±å­ å¹´é½¢: 25 ãƒ¡ãƒ¼ãƒ«: sato@company.co.jp
...     åå‰: éˆ´æœ¨ä¸€éƒ å¹´é½¢: 35 ãƒ¡ãƒ¼ãƒ«: suzuki@sample.org
...     
...     é€£çµ¡å…ˆæƒ…å ±:
...     é›»è©±ç•ªå·: 03-1234-5678, 090-9876-5432
...     éƒµä¾¿ç•ªå·: 100-0001, 160-0023
...     
...     ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ:
...     https://www.example.com
...     https://api.sample.co.jp/v1/users
...     
...     ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿:
...     2024-01-15 10:30:15 [INFO] ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ
...     2024-01-15 10:31:42 [ERROR] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼
...     2024-01-15 10:32:01 [WARN] å‡¦ç†æ™‚é–“ãŒé–¾å€¤ã‚’è¶…é
...     
...     å£²ä¸Šãƒ‡ãƒ¼ã‚¿(CSV):
...     å•†å“A, 10000, 2024-01-15
...     å•†å“B, 15000, 2024-01-16
...     å•†å“C, 8000, 2024-01-17
...     
...     æ•°å€¤ãƒ‡ãƒ¼ã‚¿: 123.45, -67.89, 1000, 0.5
...     
...     æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ: ã“ã‚Œã¯ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚Pythonã§æ­£è¦è¡¨ç¾ã‚’å­¦ç¿’ã—ã¦ã„ã¾ã™ã€‚
...     """
...     
...     # ãƒ†ã‚­ã‚¹ãƒˆè§£æã®åˆæœŸåŒ–
...     analyzer = TextAnalyzer()
...     
...     # åŸºæœ¬æƒ…å ±ã®æŠ½å‡º
...     print("\\n=== åŸºæœ¬æƒ…å ±ã®æŠ½å‡º ===")
...     extracted_info = analyzer.extract_information(sample_text)
...     for info_type, items in extracted_info.items():
...         if items:
...             print(f"{info_type}: {items}")
...     
...     # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
...     print("\\n=== ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ ===")
...     test_formats = [
...         ("tanaka@example.com", "email"),
...         ("03-1234-5678", "phone_jp"),
...         ("https://www.example.com", "url"),
...         ("100-0001", "postal_code"),
...         ("2024-01-15", "date_ymd"),
...         ("invalid-email", "email")
...     ]
...     
...     for text, format_type in test_formats:
...         is_valid = analyzer.validate_format(text, format_type)
...         status = "âœ“" if is_valid else "âœ—"
...         print(f"{status} {text} ({format_type}): {'æœ‰åŠ¹' if is_valid else 'ç„¡åŠ¹'}")
...     
...     # æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¹ã‚­ãƒ³ã‚°
...     print("\\n=== æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¹ã‚­ãƒ³ã‚° ===")
...     masked_text = analyzer.mask_sensitive_data(sample_text)
...     print("ãƒã‚¹ã‚­ãƒ³ã‚°å‰:")
...     print("ç”°ä¸­å¤ªéƒã®ãƒ¡ãƒ¼ãƒ«: tanaka@example.com, é›»è©±: 03-1234-5678")
...     print("ãƒã‚¹ã‚­ãƒ³ã‚°å¾Œ:")
...     mask_sample = "ç”°ä¸­å¤ªéƒã®ãƒ¡ãƒ¼ãƒ«: tanaka@example.com, é›»è©±: 03-1234-5678"
...     masked_sample = analyzer.mask_sensitive_data(mask_sample)
...     print(masked_sample)
...     
...     # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
...     print("\\n=== æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º ===")
...     structured_data = analyzer.extract_structured_data(sample_text)
...     for data_type, items in structured_data.items():
...         if items:
...             print(f"\\n{data_type}:")
...             for item in items:
...                 print(f"  {item}")
...     
...     # ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
...     print("\\n=== ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ ===")
...     pattern_analysis = analyzer.analyze_text_patterns(sample_text)
...     for key, value in pattern_analysis.items():
...         print(f"{key}: {value}")
...     
...     # æ¤œç´¢ã¨ç½®æ›
...     print("\\n=== æ¤œç´¢ã¨ç½®æ› ===")
...     replacements = [
...         (r'\b(ERROR|WARN)\b', r'[\1]'),  # ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒ™ãƒ«ã‚’æ‹¬å¼§ã§å›²ã‚€
...         (r'\d{4}-\d{2}-\d{2}', '[DATE]'),  # æ—¥ä»˜ã‚’[DATE]ã«ç½®æ›
...         (r'å•†å“[A-Z]', 'è£½å“X')  # å•†å“åã‚’è£½å“Xã«ç½®æ›
...     ]
...     
...     original_sample = "2024-01-15 [ERROR] å•†å“Aã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ"
...     replaced_sample = analyzer.search_and_replace(original_sample, replacements)
...     print(f"å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ: {original_sample}")
...     print(f"ç½®æ›å¾Œ: {replaced_sample}")
...     
...     # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
...     print("\\n" + analyzer.generate_summary_report(sample_text))

>>> test_text_analyzer()

=== ãƒ†ã‚­ã‚¹ãƒˆè§£æã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ ===

=== åŸºæœ¬æƒ…å ±ã®æŠ½å‡º ===
email: ['tanaka@example.com', 'sato@company.co.jp', 'suzuki@sample.org']
phone_jp: ['03-1234-5678', '090-9876-5432']
url: ['https://www.example.com', 'https://api.sample.co.jp/v1/users']
postal_code: ['100-0001', '160-0023']
date_ymd: ['2024-01-15', '2024-01-15', '2024-01-15', '2024-01-15', '2024-01-16', '2024-01-17']
time_hm: ['10:30', '10:31', '10:32']
number: ['30', '25', '35', '03', '1234', '5678', '090', '9876', '5432', '100', '0001', '160', '0023', '2024', '01', '15', '10', '30', '15', '2024', '01', '15', '10', '31', '42', '2024', '01', '15', '10', '32', '01', '10000', '2024', '01', '15', '15000', '2024', '01', '16', '8000', '2024', '01', '17', '123.45', '67.89', '1000', '0.5']
word: ['INFO', 'ERROR', 'WARN', 'CSV', 'Python']

=== ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ ===
âœ“ tanaka@example.com (email): æœ‰åŠ¹
âœ“ 03-1234-5678 (phone_jp): æœ‰åŠ¹
âœ“ https://www.example.com (url): æœ‰åŠ¹
âœ“ 100-0001 (postal_code): æœ‰åŠ¹
âœ“ 2024-01-15 (date_ymd): æœ‰åŠ¹
âœ— invalid-email (email): ç„¡åŠ¹

=== æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¹ã‚­ãƒ³ã‚° ===
ãƒã‚¹ã‚­ãƒ³ã‚°å‰:
ç”°ä¸­å¤ªéƒã®ãƒ¡ãƒ¼ãƒ«: tanaka@example.com, é›»è©±: 03-1234-5678
ãƒã‚¹ã‚­ãƒ³ã‚°å¾Œ:
ç”°ä¸­å¤ªéƒã®ãƒ¡ãƒ¼ãƒ«: ***@***.**, é›»è©±: ***-****-****

=== æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º ===

logs:
  {'timestamp': '2024-01-15 10:30:15', 'level': 'INFO', 'message': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ'}
  {'timestamp': '2024-01-15 10:31:42', 'level': 'ERROR', 'message': 'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼'}
  {'timestamp': '2024-01-15 10:32:01', 'level': 'WARN', 'message': 'å‡¦ç†æ™‚é–“ãŒé–¾å€¤ã‚’è¶…é'}

csv_data:
  {'field1': 'å•†å“A', 'field2': ' 10000', 'field3': ' 2024-01-15'}
  {'field1': 'å•†å“B', 'field2': ' 15000', 'field3': ' 2024-01-16'}
  {'field1': 'å•†å“C', 'field2': ' 8000', 'field3': ' 2024-01-17'}

users:
  {'name': 'ç”°ä¸­å¤ªéƒ', 'age': '30', 'email': 'tanaka@example.com'}
  {'name': 'ä½è—¤èŠ±å­', 'age': '25', 'email': 'sato@company.co.jp'}
  {'name': 'éˆ´æœ¨ä¸€éƒ', 'age': '35', 'email': 'suzuki@sample.org'}

=== ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ ===
word_count: 44
unique_words: 33
most_common_words: [('01', 8), ('2024', 6), ('15', 5), ('10', 3), ('com', 2)]
sentence_count: 2
avg_sentence_length: 11.0
paragraph_count: 1
number_count: 54
number_sum: 39086.05

=== æ¤œç´¢ã¨ç½®æ› ===
å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ: 2024-01-15 [ERROR] å•†å“Aã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ
ç½®æ›å¾Œ: [DATE] [[ERROR]] è£½å“Xã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ

=== ãƒ†ã‚­ã‚¹ãƒˆè§£æãƒ¬ãƒãƒ¼ãƒˆ ===
ãƒ†ã‚­ã‚¹ãƒˆé•·: 1090æ–‡å­—
å˜èªæ•°: 44
ãƒ¦ãƒ‹ãƒ¼ã‚¯å˜èªæ•°: 33
æ–‡æ•°: 2
æ®µè½æ•°: 1

ã€æŠ½å‡ºã•ã‚ŒãŸæƒ…å ±ã€‘
email: 3å€‹
  - tanaka@example.com
  - sato@company.co.jp
  - suzuki@sample.org
phone_jp: 2å€‹
  - 03-1234-5678
  - 090-9876-5432
url: 2å€‹
  - https://www.example.com
  - https://api.sample.co.jp/v1/users
postal_code: 2å€‹
  - 100-0001
  - 160-0023
date_ymd: 6å€‹
  - 2024-01-15
  - 2024-01-15
  - 2024-01-15
  ... ä»– 3å€‹
time_hm: 3å€‹
  - 10:30
  - 10:31
  - 10:32
number: 54å€‹
  - 30
  - 25
  - 35
  ... ä»– 51å€‹
word: 5å€‹
  - INFO
  - ERROR
  - WARN
  ... ä»– 2å€‹

ã€é »å‡ºå˜èª TOP5ã€‘
01: 8å›
2024: 6å›
15: 5å›
10: 3å›
com: 2å›
```

## ãƒ‡ãƒ¼ã‚¿æ§‹é€  - collectionsãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®æ´»ç”¨

```python
>>> from collections import defaultdict, Counter, deque, namedtuple, OrderedDict, ChainMap
>>> from datetime import datetime
>>> import heapq

>>> class AdvancedDataStructures:
...     """é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®æ´»ç”¨ä¾‹"""
...     
...     def demonstrate_counter(self):
...         """Counterã®ä½¿ç”¨ä¾‹"""
...         print("=== Counter ã®ä½¿ç”¨ä¾‹ ===")
...         
...         # æ–‡å­—ã®é »åº¦ã‚«ã‚¦ãƒ³ãƒˆ
...         text = "hello world python programming"
...         char_count = Counter(text)
...         print(f"æ–‡å­—ã®é »åº¦: {char_count.most_common(5)}")
...         
...         # å˜èªã®é »åº¦ã‚«ã‚¦ãƒ³ãƒˆ
...         words = text.split()
...         word_count = Counter(words)
...         print(f"å˜èªã®é »åº¦: {word_count}")
...         
...         # ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°ã®åˆ†æä¾‹
...         access_logs = [
...             "192.168.1.100", "192.168.1.101", "192.168.1.100",
...             "10.0.0.1", "192.168.1.100", "10.0.0.1", "192.168.1.102"
...         ]
...         ip_count = Counter(access_logs)
...         print(f"IPã‚¢ãƒ‰ãƒ¬ã‚¹åˆ¥ã‚¢ã‚¯ã‚»ã‚¹æ•°: {ip_count.most_common()}")
...         
...         # CounteråŒå£«ã®æ¼”ç®—
...         counter1 = Counter("aabbc")
...         counter2 = Counter("abc")
...         print(f"Counter1: {counter1}")
...         print(f"Counter2: {counter2}")
...         print(f"åŠ ç®—: {counter1 + counter2}")
...         print(f"æ¸›ç®—: {counter1 - counter2}")
...         print(f"ç©é›†åˆ: {counter1 & counter2}")
...     
...     def demonstrate_defaultdict(self):
...         """defaultdictã®ä½¿ç”¨ä¾‹"""
...         print("\\n=== defaultdict ã®ä½¿ç”¨ä¾‹ ===")
...         
...         # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã®ä¾‹
...         students = [
...             ("ç”°ä¸­", "æ•°å­¦"), ("ä½è—¤", "è‹±èª"), ("éˆ´æœ¨", "æ•°å­¦"),
...             ("é«˜æ©‹", "ç†ç§‘"), ("å±±ç”°", "è‹±èª"), ("æ¸¡è¾º", "æ•°å­¦")
...         ]
...         
...         # é€šå¸¸ã®è¾æ›¸ã§ã¯è¤‡é›‘
...         regular_dict = {}
...         for name, subject in students:
...             if subject not in regular_dict:
...                 regular_dict[subject] = []
...             regular_dict[subject].append(name)
...         
...         # defaultdictãªã‚‰ç°¡æ½”
...         grouped = defaultdict(list)
...         for name, subject in students:
...             grouped[subject].append(name)
...         
...         print("ç§‘ç›®åˆ¥ç”Ÿå¾’ä¸€è¦§:")
...         for subject, names in grouped.items():
...             print(f"  {subject}: {names}")
...         
...         # ãƒã‚¹ãƒˆã—ãŸ defaultdict
...         sales_data = defaultdict(lambda: defaultdict(int))
...         sales_records = [
...             ("2024-01", "å•†å“A", 100),
...             ("2024-01", "å•†å“B", 150),
...             ("2024-02", "å•†å“A", 120),
...             ("2024-02", "å•†å“C", 80)
...         ]
...         
...         for month, product, amount in sales_records:
...             sales_data[month][product] += amount
...         
...         print("\\næœˆåˆ¥ãƒ»å•†å“åˆ¥å£²ä¸Š:")
...         for month, products in sales_data.items():
...             print(f"  {month}:")
...             for product, amount in products.items():
...                 print(f"    {product}: {amount}")
...     
...     def demonstrate_deque(self):
...         """dequeã®ä½¿ç”¨ä¾‹"""
...         print("\\n=== deque ã®ä½¿ç”¨ä¾‹ ===")
...         
...         # ä¸¡ç«¯ã‚­ãƒ¥ãƒ¼ã¨ã—ã¦ã®ä½¿ç”¨
...         task_queue = deque()
...         
...         # å³ç«¯ã«è¿½åŠ ï¼ˆé€šå¸¸ã®ã‚­ãƒ¥ãƒ¼æ“ä½œï¼‰
...         task_queue.append("ã‚¿ã‚¹ã‚¯1")
...         task_queue.append("ã‚¿ã‚¹ã‚¯2")
...         task_queue.append("ã‚¿ã‚¹ã‚¯3")
...         print(f"ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼: {list(task_queue)}")
...         
...         # å·¦ç«¯ã‹ã‚‰å–å¾—ï¼ˆFIFOï¼‰
...         first_task = task_queue.popleft()
...         print(f"å®Ÿè¡Œã™ã‚‹ã‚¿ã‚¹ã‚¯: {first_task}")
...         print(f"æ®‹ã‚Šã‚¿ã‚¹ã‚¯: {list(task_queue)}")
...         
...         # å„ªå…ˆã‚¿ã‚¹ã‚¯ã‚’å·¦ç«¯ã«è¿½åŠ 
...         task_queue.appendleft("ç·Šæ€¥ã‚¿ã‚¹ã‚¯")
...         print(f"ç·Šæ€¥ã‚¿ã‚¹ã‚¯è¿½åŠ å¾Œ: {list(task_queue)}")
...         
...         # å›ºå®šã‚µã‚¤ã‚ºã®ãƒãƒƒãƒ•ã‚¡ï¼ˆæœ€è¿‘ã®Nä»¶ã‚’ä¿æŒï¼‰
...         recent_actions = deque(maxlen=3)
...         actions = ["ã‚¢ã‚¯ã‚·ãƒ§ãƒ³1", "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³2", "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³3", "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³4", "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³5"]
...         
...         for action in actions:
...             recent_actions.append(action)
...             print(f"æœ€è¿‘ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {list(recent_actions)}")
...     
...     def demonstrate_namedtuple(self):
...         """namedtupleã®ä½¿ç”¨ä¾‹"""
...         print("\\n=== namedtuple ã®ä½¿ç”¨ä¾‹ ===")
...         
...         # åº§æ¨™ç‚¹ã®å®šç¾©
...         Point = namedtuple('Point', ['x', 'y'])
...         p1 = Point(3, 4)
...         p2 = Point(0, 0)
...         
...         print(f"ç‚¹1: {p1}")
...         print(f"ç‚¹1ã®xåº§æ¨™: {p1.x}")
...         print(f"ç‚¹1ã®yåº§æ¨™: {p1.y}")
...         
...         # è·é›¢è¨ˆç®—
...         distance = ((p1.x - p2.x)**2 + (p1.y - p2.y)**2)**0.5
...         print(f"åŸç‚¹ã‹ã‚‰ã®è·é›¢: {distance}")
...         
...         # å¾“æ¥­å“¡æƒ…å ±ã®å®šç¾©
...         Employee = namedtuple('Employee', ['id', 'name', 'department', 'salary'])
...         employees = [
...             Employee(1, "ç”°ä¸­å¤ªéƒ", "é–‹ç™º", 500000),
...             Employee(2, "ä½è—¤èŠ±å­", "å–¶æ¥­", 450000),
...             Employee(3, "éˆ´æœ¨ä¸€éƒ", "é–‹ç™º", 520000)
...         ]
...         
...         print("\\nå¾“æ¥­å“¡æƒ…å ±:")
...         for emp in employees:
...             print(f"  ID:{emp.id} {emp.name} ({emp.department}) - {emp.salary:,}å††")
...         
...         # éƒ¨ç½²åˆ¥å¹³å‡çµ¦ä¸
...         dept_salaries = defaultdict(list)
...         for emp in employees:
...             dept_salaries[emp.department].append(emp.salary)
...         
...         print("\\néƒ¨ç½²åˆ¥å¹³å‡çµ¦ä¸:")
...         for dept, salaries in dept_salaries.items():
...             avg_salary = sum(salaries) / len(salaries)
...             print(f"  {dept}: {avg_salary:,.0f}å††")
...     
...     def demonstrate_chainmap(self):
...         """ChainMapã®ä½¿ç”¨ä¾‹"""
...         print("\\n=== ChainMap ã®ä½¿ç”¨ä¾‹ ===")
...         
...         # è¨­å®šã®éšå±¤ç®¡ç†
...         default_config = {
...             "host": "localhost",
...             "port": 8080,
...             "debug": False,
...             "timeout": 30
...         }
...         
...         user_config = {
...             "port": 9000,
...             "debug": True
...         }
...         
...         env_config = {
...             "host": "production-server.com"
...         }
...         
...         # å„ªå…ˆé †ä½: env_config > user_config > default_config
...         config = ChainMap(env_config, user_config, default_config)
...         
...         print("çµ±åˆè¨­å®š:")
...         for key, value in config.items():
...             print(f"  {key}: {value}")
...         
...         print(f"\\nhostè¨­å®šã®å–å¾—: {config['host']}")
...         print(f"portè¨­å®šã®å–å¾—: {config['port']}")
...         
...         # æ–°ã—ã„è¨­å®šã®è¿½åŠ 
...         runtime_config = {"max_connections": 100}
...         extended_config = ChainMap(runtime_config, config)
...         print(f"\\nå®Ÿè¡Œæ™‚è¨­å®šè¿½åŠ å¾Œã®max_connections: {extended_config.get('max_connections')}")

>>> # å®Ÿç”¨çš„ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®çµ„ã¿åˆã‚ã›ä¾‹
>>> class LogAnalyzer:
...     """ãƒ­ã‚°è§£æã‚·ã‚¹ãƒ†ãƒ ï¼ˆé«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ä½¿ç”¨ï¼‰"""
...     
...     def __init__(self):
...         self.log_entries = deque(maxlen=1000)  # æœ€æ–°1000ä»¶ã®ãƒ­ã‚°ã‚’ä¿æŒ
...         self.error_count = Counter()
...         self.hourly_stats = defaultdict(lambda: defaultdict(int))
...         
...         # ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®æ§‹é€ ã‚’å®šç¾©
...         self.LogEntry = namedtuple('LogEntry', 
...                                   ['timestamp', 'level', 'source', 'message'])
...     
...     def add_log_entry(self, timestamp, level, source, message):
...         """ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®è¿½åŠ """
...         entry = self.LogEntry(timestamp, level, source, message)
...         self.log_entries.append(entry)
...         
...         # ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒ™ãƒ«ã®çµ±è¨ˆ
...         self.error_count[level] += 1
...         
...         # æ™‚é–“åˆ¥çµ±è¨ˆ
...         hour = timestamp.hour
...         self.hourly_stats[hour][level] += 1
...     
...     def get_error_summary(self):
...         """ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼ã®å–å¾—"""
...         return dict(self.error_count)
...     
...     def get_hourly_report(self):
...         """æ™‚é–“åˆ¥ãƒ¬ãƒãƒ¼ãƒˆã®å–å¾—"""
...         report = {}
...         for hour, stats in self.hourly_stats.items():
...             report[hour] = dict(stats)
...         return report
...     
...     def get_recent_errors(self, error_level="ERROR", count=5):
...         """æœ€è¿‘ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’å–å¾—"""
...         errors = [entry for entry in self.log_entries 
...                  if entry.level == error_level]
...         return list(errors)[-count:]

>>> # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ãƒ†ã‚¹ãƒˆ
>>> def test_advanced_data_structures():
...     """é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ãƒ†ã‚¹ãƒˆ"""
...     print("=== é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ãƒ†ã‚¹ãƒˆ ===")
...     
...     demo = AdvancedDataStructures()
...     
...     # å„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
...     demo.demonstrate_counter()
...     demo.demonstrate_defaultdict()
...     demo.demonstrate_deque()
...     demo.demonstrate_namedtuple()
...     demo.demonstrate_chainmap()
...     
...     # ãƒ­ã‚°è§£æã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
...     print("\\n=== ãƒ­ã‚°è§£æã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ ===")
...     log_analyzer = LogAnalyzer()
...     
...     # ã‚µãƒ³ãƒ—ãƒ«ãƒ­ã‚°ã®è¿½åŠ 
...     sample_logs = [
...         (datetime(2024, 1, 15, 9, 30), "INFO", "auth", "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ­ã‚°ã‚¤ãƒ³"),
...         (datetime(2024, 1, 15, 9, 31), "ERROR", "db", "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼"),
...         (datetime(2024, 1, 15, 10, 15), "WARN", "api", "APIå¿œç­”æ™‚é–“è¶…é"),
...         (datetime(2024, 1, 15, 10, 30), "ERROR", "auth", "èªè¨¼å¤±æ•—"),
...         (datetime(2024, 1, 15, 11, 45), "INFO", "web", "ãƒšãƒ¼ã‚¸ã‚¢ã‚¯ã‚»ã‚¹"),
...         (datetime(2024, 1, 15, 11, 50), "ERROR", "db", "ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ"),
...     ]
...     
...     for timestamp, level, source, message in sample_logs:
...         log_analyzer.add_log_entry(timestamp, level, source, message)
...     
...     # ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼
...     error_summary = log_analyzer.get_error_summary()
...     print("ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒ™ãƒ«åˆ¥çµ±è¨ˆ:")
...     for level, count in error_summary.items():
...         print(f"  {level}: {count}ä»¶")
...     
...     # æ™‚é–“åˆ¥ãƒ¬ãƒãƒ¼ãƒˆ
...     hourly_report = log_analyzer.get_hourly_report()
...     print("\\næ™‚é–“åˆ¥ãƒ­ã‚°çµ±è¨ˆ:")
...     for hour in sorted(hourly_report.keys()):
...         stats = hourly_report[hour]
...         print(f"  {hour:02d}æ™‚å°: {dict(stats)}")
...     
...     # æœ€è¿‘ã®ã‚¨ãƒ©ãƒ¼
...     recent_errors = log_analyzer.get_recent_errors("ERROR", 3)
...     print("\\næœ€è¿‘ã®ã‚¨ãƒ©ãƒ¼:")
...     for error in recent_errors:
...         print(f"  {error.timestamp} [{error.level}] {error.source}: {error.message}")

>>> test_advanced_data_structures()

=== é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ãƒ†ã‚¹ãƒˆ ===
=== Counter ã®ä½¿ç”¨ä¾‹ ===
æ–‡å­—ã®é »åº¦: [('o', 3), ('r', 3), ('m', 3), (' ', 3), ('g', 2)]
å˜èªã®é »åº¦: Counter({'hello': 1, 'world': 1, 'python': 1, 'programming': 1})
IPã‚¢ãƒ‰ãƒ¬ã‚¹åˆ¥ã‚¢ã‚¯ã‚»ã‚¹æ•°: [('192.168.1.100', 3), ('10.0.0.1', 2), ('192.168.1.101', 1), ('192.168.1.102', 1)]
Counter1: Counter({'a': 2, 'b': 2, 'c': 1})
Counter2: Counter({'a': 1, 'b': 1, 'c': 1})
åŠ ç®—: Counter({'a': 3, 'b': 3, 'c': 2})
æ¸›ç®—: Counter({'a': 1, 'b': 1})
ç©é›†åˆ: Counter({'a': 1, 'b': 1, 'c': 1})

=== defaultdict ã®ä½¿ç”¨ä¾‹ ===
ç§‘ç›®åˆ¥ç”Ÿå¾’ä¸€è¦§:
  æ•°å­¦: ['ç”°ä¸­', 'éˆ´æœ¨', 'æ¸¡è¾º']
  è‹±èª: ['ä½è—¤', 'å±±ç”°']
  ç†ç§‘: ['é«˜æ©‹']

æœˆåˆ¥ãƒ»å•†å“åˆ¥å£²ä¸Š:
  2024-01:
    å•†å“A: 100
    å•†å“B: 150
  2024-02:
    å•†å“A: 120
    å•†å“C: 80

=== deque ã®ä½¿ç”¨ä¾‹ ===
ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼: ['ã‚¿ã‚¹ã‚¯1', 'ã‚¿ã‚¹ã‚¯2', 'ã‚¿ã‚¹ã‚¯3']
å®Ÿè¡Œã™ã‚‹ã‚¿ã‚¹ã‚¯: ã‚¿ã‚¹ã‚¯1
æ®‹ã‚Šã‚¿ã‚¹ã‚¯: ['ã‚¿ã‚¹ã‚¯2', 'ã‚¿ã‚¹ã‚¯3']
ç·Šæ€¥ã‚¿ã‚¹ã‚¯è¿½åŠ å¾Œ: ['ç·Šæ€¥ã‚¿ã‚¹ã‚¯', 'ã‚¿ã‚¹ã‚¯2', 'ã‚¿ã‚¹ã‚¯3']
æœ€è¿‘ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: ['ã‚¢ã‚¯ã‚·ãƒ§ãƒ³1']
æœ€è¿‘ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: ['ã‚¢ã‚¯ã‚·ãƒ§ãƒ³1', 'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³2']
æœ€è¿‘ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: ['ã‚¢ã‚¯ã‚·ãƒ§ãƒ³1', 'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³2', 'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³3']
æœ€è¿‘ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: ['ã‚¢ã‚¯ã‚·ãƒ§ãƒ³2', 'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³3', 'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³4']
æœ€è¿‘ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: ['ã‚¢ã‚¯ã‚·ãƒ§ãƒ³3', 'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³4', 'ã‚¢ã‚¯ã‚·ãƒ§ãƒ³5']

=== namedtuple ã®ä½¿ç”¨ä¾‹ ===
ç‚¹1: Point(x=3, y=4)
ç‚¹1ã®xåº§æ¨™: 3
ç‚¹1ã®yåº§æ¨™: 4
åŸç‚¹ã‹ã‚‰ã®è·é›¢: 5.0

å¾“æ¥­å“¡æƒ…å ±:
  ID:1 ç”°ä¸­å¤ªéƒ (é–‹ç™º) - 500,000å††
  ID:2 ä½è—¤èŠ±å­ (å–¶æ¥­) - 450,000å††
  ID:3 éˆ´æœ¨ä¸€éƒ (é–‹ç™º) - 520,000å††

éƒ¨ç½²åˆ¥å¹³å‡çµ¦ä¸:
  é–‹ç™º: 510,000å††
  å–¶æ¥­: 450,000å††

=== ChainMap ã®ä½¿ç”¨ä¾‹ ===
çµ±åˆè¨­å®š:
  host: production-server.com
  port: 9000
  debug: True
  timeout: 30

hostè¨­å®šã®å–å¾—: production-server.com
portè¨­å®šã®å–å¾—: 9000

å®Ÿè¡Œæ™‚è¨­å®šè¿½åŠ å¾Œã®max_connections: 100

=== ãƒ­ã‚°è§£æã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ ===
ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒ™ãƒ«åˆ¥çµ±è¨ˆ:
  INFO: 2ä»¶
  ERROR: 3ä»¶
  WARN: 1ä»¶

æ™‚é–“åˆ¥ãƒ­ã‚°çµ±è¨ˆ:
  09æ™‚å°: {'INFO': 1, 'ERROR': 1}
  10æ™‚å°: {'WARN': 1, 'ERROR': 1}
  11æ™‚å°: {'INFO': 1, 'ERROR': 1}

æœ€è¿‘ã®ã‚¨ãƒ©ãƒ¼:
  2024-01-15 09:31:00 [ERROR] db: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼
  2024-01-15 10:30:00 [ERROR] auth: èªè¨¼å¤±æ•—
  2024-01-15 11:50:00 [ERROR] db: ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
```

## ã¾ã¨ã‚ï¼šPythonæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æ´»ç”¨

ã“ã®ç« ã§å­¦ã‚“ã ã“ã¨ã‚’ã¾ã¨ã‚ã¾ã—ã‚‡ã†ï¼š

### ä¸»è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ç‰¹å¾´
1. **datetime**: æ—¥æ™‚ã®æ“ä½œã€è¨ˆç®—ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
2. **os/pathlib**: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ“ä½œ
3. **json**: JSONå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†
4. **re**: æ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
5. **collections**: é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ 

### å®Ÿç”¨çš„ãªå¿œç”¨ä¾‹
- **å‹¤æ€ ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ **: datetime, validation
- **ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ **: pathlib, os, shutil
- **è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ **: json, validation
- **ãƒ†ã‚­ã‚¹ãƒˆè§£æ**: re, collections.Counter
- **ãƒ­ã‚°è§£æ**: collectionså…¨èˆ¬

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ãƒ¡ãƒ¢ãƒªåŠ¹ç‡
```python
# åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®é¸æŠ
Counter("abcabc")           # é »åº¦ã‚«ã‚¦ãƒ³ãƒˆ
defaultdict(list)           # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
deque(maxlen=1000)         # å›ºå®šã‚µã‚¤ã‚ºãƒãƒƒãƒ•ã‚¡
namedtuple('Point', 'x y')  # è»½é‡ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
```

### ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
1. **é©åˆ‡ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®é¸æŠ**: è¦ä»¶ã«å¿œã˜ãŸæœ€é©ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
2. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: ä¾‹å¤–å‡¦ç†ã®é©åˆ‡ãªå®Ÿè£…
3. **å‹ãƒ’ãƒ³ãƒˆ**: å¯èª­æ€§ã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ€§ã®å‘ä¸Š
4. **è¨­å®šã®åˆ†é›¢**: ç’°å¢ƒåˆ¥è¨­å®šã®ç®¡ç†
5. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®æœ€é©åŒ–

### çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚‹ç›¸ä¹—åŠ¹æœ
```python
# è¤‡æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®çµ„ã¿åˆã‚ã›
config = json.load(f)                    # JSONè¨­å®šèª­ã¿è¾¼ã¿
log_file = Path(config['log_path'])      # pathlib ã§ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
entries = Counter()                       # collections ã§ã‚«ã‚¦ãƒ³ãƒˆ
pattern = re.compile(config['pattern'])  # æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
```

æ¬¡ã®ç« ã§ã¯ã€**Pythoné–‹ç™ºã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹**ã«ã¤ã„ã¦å­¦ã³ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆã€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç®¡ç†ã€ä»®æƒ³ç’°å¢ƒãªã©ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªé–‹ç™ºã«å¿…è¦ãªçŸ¥è­˜ã‚’ç¿’å¾—ã—ã¾ã—ã‚‡ã†ï¼

---

**ç¬¬19ç« åŸ·ç­†å®Œäº†ãƒ­ã‚°:**
ç¬¬19ç« ã§ã¯Pythonæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä¸»è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åŒ…æ‹¬çš„ã«å­¦ç¿’ã€‚datetimeã€os/pathlibã€jsonã€reã€collectionsã®åŸºæœ¬ã‹ã‚‰é«˜åº¦ãªæ´»ç”¨ã¾ã§æ®µéšçš„ã«èª¬æ˜ã€‚å®Ÿè·µä¾‹ã¨ã—ã¦å‹¤æ€ ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†ã€è¨­å®šç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã€ãƒ†ã‚­ã‚¹ãƒˆè§£æã‚·ã‚¹ãƒ†ãƒ ã€ãƒ­ã‚°è§£æã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã€‚å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚‹ç›¸ä¹—åŠ¹æœã‚‚å«ã‚€å®Œå…¨ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ´»ç”¨æ–¹æ³•ã‚’å®Ÿè£…ã€‚æ¬¡ã¯ç¬¬20ç« ã®é–‹ç™ºãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«é€²ã¿ã¾ã™ã€‚